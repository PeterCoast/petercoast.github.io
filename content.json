{"meta":{"title":"PeterCoast的hexo","subtitle":"- hexo","description":"PeterCoast, hexo, PeterCoast的hexo","author":"PeterCoast","url":"https://petercoast.github.io","root":"/"},"pages":[],"posts":[{"title":"用Python爬取5000张手机高清壁纸","slug":"用Python爬取5000张手机高清壁纸","date":"2021-08-01T04:17:31.000Z","updated":"2021-08-01T05:20:16.664Z","comments":true,"path":"2021/08/01/用Python爬取5000张手机高清壁纸/","link":"","permalink":"https://petercoast.github.io/2021/08/01/%E7%94%A8Python%E7%88%AC%E5%8F%965000%E5%BC%A0%E6%89%8B%E6%9C%BA%E9%AB%98%E6%B8%85%E5%A3%81%E7%BA%B8/","excerpt":"千张壁纸秒爬取","text":"千张壁纸秒爬取 数据源分析爬取目标图片首页地址为：https://www.3gbizhi.com/sjbz/index_1.html，该网站壁纸质量不错，清晰度也非常好，重点是对爬虫也非常友善，试了几次，爬取速度都可以，因此大家应该把该网站用于学习目的。 使用的 Python 模块本次使用 requests，re，threading。 threading 模块将在本案例中，进行分页多线程抓取。 重点学习内容爬虫基本套路 多线程图片爬虫 通过小图获取大图 列表页分析分析列表的时候发现，该网站可以直接通过，修改列表页图片地址获取高清地址，有这样的技巧存在，就能大幅度减少爬虫代码编写量，具体如下 通过浏览器检查图片标签，获得如下图所示图片地址，即 https://pic.3gbizhi.com/2020/1214/20201214112632727.jpg.476.780.jpg 在浏览器中打开该地址，得到一张图片预览地址，去除 .476.780 相关内容，直接获取到大图地址，即 https://pic.3gbizhi.com/2020/1214/20201214112632727.jpg既然可以通过列表页直接获取大图地址，那针对该网站的爬取，直接通过列表页即可实现。下面就可以针对分析进行需求的整理工作 整理需求如下 爬取目标网站列表页； 分析图片大图链接； 请求图片，保存图片。 编码时间在上文针对列表页面进行了数据上的分析，接下来就可以对其进行代码编写了。 编写图片地址提取代码，该代码的重点在于，需要将图片地址后面的缩放进行处理，即下述代码 url[:url.find(&#39;jpg&#39;)+3] 部分内容，下文中的正则表达式部分需要特别注意，在网站上右键查看的源码与服务器返回的代码存在差异，测试时需针对服务器返回进行匹配。 下文代码中 save_image 在后文涉及。 import requests import re import threading headers = &#123; &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) &quot;&#125; # 循环获取 URL def get_image(base_url): res = requests.get(url=base_url, headers=headers) if res is not None: html = res.text # 正则表达式提取数据 pattern = re.compile( &#39;&lt;img lazysrc=&quot;(.*?)&quot; lazysrc2x=&quot;.*?&quot; width=&quot;221&quot; height=&quot;362&quot; alt=&quot;.*?&quot; title=&quot;(.*?)&quot;&#39;) match_list = pattern.findall(html) for url, title in match_list: # url 字符串进行处理，去除缩略图部分 save_image(url[:url.find(&#39;jpg&#39;)+3], title) print(match_list) 此时获取到的就是图片的真实地址，调用 save_image 函数，对远程图片进行存储。其中 title 为图片存储地址。 def save_image(url, title): try: print(f&quot;&#123;title&#125; - &#123;url&#125;&quot;) res = requests.get(url=url, headers=headers) if res is not None: html = res.content with open(f&quot;images/&#123;title&#125;.jpg&quot;, &quot;wb+&quot;) as f: f.write(res.content) except Exception as e: print(e) 最后使用多线程进行爬取，开启 5 个线程，当所有线程结束运行时，停止整体代码。 if __name__ == &#39;__main__&#39;: num = 0 # 最多开启5个线程 semaphore = threading.BoundedSemaphore(5) for index in range(189): t = threading.Thread(target=get_image, args=( f&quot;https://www.3gbizhi.com/sjbz/index_&#123;index&#125;.html&quot;,)) t.start() while threading.active_count() != 1: pass else: print(&#39;所有线程运行完毕&#39;) 运行我们的爬虫程序，会看到图片批量的存储到了本地。 抓取结果展示时间抓取到非常多优质的手机壁纸，换到手机不能用，都用不完了 完整代码下载地址：main.py代码编写过程中，顺手爬取了一堆图片，可以提前预览一波，看看图，在决定是否运行这段代码。 下载链接： 3k张壁纸 密码：1188","categories":[],"tags":[]}],"categories":[],"tags":[]}